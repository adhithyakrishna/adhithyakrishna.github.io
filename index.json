[{"content":"Solution for leetcode 819 Golang Java  Golang solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  func mostCommonWord(paragraph string, banned []string) string { var sb strings.Builder bannedMap := make(map[string]bool) for _, data := range banned { bannedMap[data] = true } wordCounts := make(map[string]int) var max string for _, ch := range paragraph { if string(ch) == \u0026#34; \u0026#34; || string(ch) == \u0026#34;,\u0026#34; { if sb.Len() \u0026gt; 0 { max = addWordToMap(wordCounts, sb, max, bannedMap) sb.Reset() } } else { if unicode.IsLetter(ch) { sb.WriteString(string(ch)) } } } if sb.Len() \u0026gt; 0 { max = addWordToMap(wordCounts, sb, max, bannedMap) } return max } func addWordToMap(wordCounts map[string]int, sb strings.Builder, max string, bannedMap map[string]bool) string { word := strings.ToLower(sb.String()) wordCounts[word] += 1 if !bannedMap[word] \u0026amp;\u0026amp; wordCounts[word] \u0026gt; wordCounts[max] { max = word } return max }   References:\n Are Maps pass by reference in go ?    Java solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  class Solution { public String mostCommonWord(String paragraph, String[] banned) { Set\u0026lt;String\u0026gt; bannedSet = new HashSet\u0026lt;String\u0026gt;(); for(String ban: banned) { bannedSet.add(ban); } StringBuffer sb = new StringBuffer(); Map\u0026lt;String, Integer\u0026gt; dataMap = new HashMap\u0026lt;String, Integer\u0026gt;(); String max = \u0026#34;\u0026#34;; for(char ch : paragraph.toCharArray()) { if(ch == \u0026#39; \u0026#39; || ch == \u0026#39;,\u0026#39;) { if(sb.length() \u0026gt; 0) { max = addWordToMap(sb, bannedSet, dataMap, max); sb.setLength(0); } } else { if(Character.isAlphabetic(ch)) { sb.append(ch); } } } if(sb.length() \u0026gt; 0) { max = addWordToMap(sb, bannedSet, dataMap, max); } return max; } public String addWordToMap(StringBuffer sb, Set\u0026lt;String\u0026gt; bannedSet, Map\u0026lt;String, Integer\u0026gt; dataMap, String max) { String word = sb.toString().toLowerCase(); if(bannedSet.contains(word)) return max; dataMap.put(word, dataMap.getOrDefault(word, 0) + 1); if(dataMap.get(word) \u0026gt; dataMap.getOrDefault(max, 0)) { return word; } return max; } }       'use strict'; var containerId = JSON.parse(\"\\\"2e3d604510cf6c4c\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  Time complexity : O(N + M)\nSpace complexity : O(N + M) ","description":"Solution for Leetcode 819","id":0,"section":"tech","tags":null,"title":"Most Common word","uri":"https://adhithyakrishna.github.io/tech/leetcode/leetcode819/"},{"content":"Solution for leetcode 977 Golang Java  Golang solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  func sortedSquares(nums []int) []int { result := make([]int, len(nums)) start := 0 end := len(nums)-1 index := len(nums)-1 for start \u0026lt;= end { if(abs(nums[start]) \u0026gt;= abs(nums[end])) { result[index] = nums[start] * nums[start] start++ } else { result[index] = nums[end] * nums[end] end-- } index-- } return result } func abs(x int) int { if(x \u0026lt; 0) { return x * -1; } return x }     Java solution 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  class Solution { public int[] sortedSquares(int[] nums) { int[] result = new int[nums.length]; int start = 0; int end = nums.length - 1; int index = nums.length - 1; while(start \u0026lt;= end) { if(abs(nums[start]) \u0026lt;= abs(nums[end])) { result[index] = nums[end] * nums[end]; end--; } else { result[index] = nums[start] * nums[start]; start++; } index--; } return result; } public int abs(int data) { return data \u0026lt; 0 ? data * -1 : data; } }       'use strict'; var containerId = JSON.parse(\"\\\"216afdbf67550f67\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  Time complexity : O(N)\nSpace complexity : O(N) ","description":"Solution for Leetcode 977","id":1,"section":"tech","tags":null,"title":"Squares of a sorted array","uri":"https://adhithyakrishna.github.io/tech/leetcode/leetcode977/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nIntroduction Container orchestration system = Container + Orchestration\nWhat are containers  Containers have their own processes, network and mounts Multiple containers can share the underlying operating system kernel.  Docker (most popular container technology).\nProblems before containers  Application component and services being incompatible with underlying OS. Compatibility between services, libraries and dependencies on the OS. Compatability checks had to be make during every component upgrade AKA matrix from hell. Onboarding a new developer / setting up a local instance was difficult.  With docker  Each component can run in its own container with its own libraries and dependencies. Docker is compatible with any operating systems. Onboarding a new developer / setting up a local instance is very easy.  Os components and responsibilities All operating sytems consists of two important components\n OS Kernel Software  Os kernel is responsible for interacting with underlying hardware. Custom software differentiates operating systems from each other. Docker container shares the underlying kernel of docker host. Docker is not meant to virualize and run different operating systems on the same hardware. The main purpose is to containerize and ship them.\nDocker vs Virtual machines  Containers vs Virtual Machine: https://www.udemy.com/course/learn-kubernetes/   In case of docker we have\n Underlying hardware infrastructure. Operating system Docker installed on the OS (which is responsible for managing the containers that run with libraries and dependencies).  In case of virual machine\n Underlying hardware infrastructure Operating system Hypervisor (ESX or virtualization) Virtual machine Virual machine has its own OS inside Dependencies Application  The overhead causes higher utilization of underlying resources because there are multiple operating systems and kernel running. The Virtual machine is heavy and consume high disk space (Gigabytes) whereas Docker containers a re light weight and are usually mega bytes in size.\nDocker containers boot up faster (within seconds). VM takes minutes to boot up as it needs to boot up the entire OS.\nDocker has less isolation as more resources (like kernel) are shared between containers.\nFor VMs, there is complete isolation. Since VM does not directly rely on underlying OS or kernel, we can run different OS such as linux / windows based on same hypervisor.\n\u0026ldquo;Hypervisors and containers are used for different purposes. Hypervisors are used to create and run virtual machines (VMs), which each have their own complete operating systems, securely isolated from the others. In contrast to VMs, containers package up just an app and its related services. This makes them more lightweight and portable than VMs, so they are often used for fast and flexible application development and movement.\u0026rdquo;\nReference : https://www.vmware.com/topics/glossary/content/hypervisor.html?resource=cat-1023790256#cat-1023790256 Image vs Containers An image is a package or a template that is used to create one or more containers.\nContainers are running instances of that image that are isolated and have their own environments and set of processes.\nAdvantage of containers Traditonally, developers developed applications and hand it over to Ops team to deploy and manage it in production environments along with some instructions. If they hit an issue, they would have to work with developers to resolve it.\nWith docker, major portion of this infrastructure setup is now in the hands of developers in form of Docker file. The instructions that were put to gether previously (handed off to the ops team) can now put together easily into a Dockerfile (to create an image for their application). The image can run on any container platform and is guaranteed to run the same way everywhere. Ops team can now use the image to deploy the application. Since OPS team are not modifying it, it continues to work the same when deployed in production.\n","description":"Introduction to Kubernetes","id":2,"section":"tech","tags":null,"title":"Introduction","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/introduction/"},{"content":"  Civil War It was a blissful morning until I heard a blaring noise,\nA noise of an explosion followed by shrill shouts and cries.\nI saw a ginourmous object being dropped down from an hover,\nBefore I could react, everything was already over.\nAs I regained my bleared vision, I couldn\u0026rsquo;t believe my eyes,\nAn enormous blanket of smog covered the scarlet sky.\nEverything was tattered and demolished from the intense mar,\nThey had destroyed my entire village in the name of civil war.\nYou know,\nOur ancestors inhabited this village and their origins cannot be dated,\nMost ancient, revered and civilized that their sanctity cannot be stated.\nThe vast stretch of this fertile land is now wilted and withered,\nMy beautiful village that once flourished lies soulless and desimated.\nThe survivors were forced in to a refugee camp, a so-called safe place,\nThousands of us were coerced to survive in this constricted space.\nIn the name of displaced refugees, we were treated like an animal herd.\nOur desperate cries for food and neccessities were ignored or left unheard.\nMy interim stay at this camp were the most unbearable days,\nEach and every one of us suffered abuse in numerous ways.\nWomen and hapless infants were the most exploited victims,\nThese tortures was carried out to fulfill the dictator\u0026rsquo;s dictums.\nThe horrendous act of inhumanity increased each day,\nRape and brutal abuse evolved into a cold-blooded slay.\nLoosing my bloodmates one by one was something my heart couldn\u0026rsquo;t bear,\nAll of them left this earth having their soul imprinted with fear.\nAs the seconds of darkness fleeted incessantly, arrived my final day.\nI had not choice but to participate in this tragic play.\nA pointy large bullet was fired, it pierced right in my heart,\nI wish to leave back this final message as my soul starts to depart.\nFinal message ------------- \u0026quot;You were born on this earth bringing nothing, And that is how you'll leave. Your debauched ways of acquiring something, Will definitely end up in grieve. Everyone was born with an empty hand, No person was alloted a permanent berth. This entire Earth is mother nature's land, And this is the eternal truth. No force except the nature can, determine your birth or death. Remember, Every soul killed here will revive again like the beatified holy man of Nazareth.\u0026quot; -Adhi\nThis poem is based on real life incidents Sri lankan civil war and is dedicated to those who lost their lives to the WAR.\n","description":"","id":3,"section":"literature","tags":null,"title":"Civil War","uri":"https://adhithyakrishna.github.io/literature/poems/civilwar/"},{"content":"This post was inspired by an awesome tech talk by Florian Patan at GopherCon UK in 2018 where he goes over creating a goservice in 30 minutes. The interesting take away from the talk was the use of dependency injection to insert a logger instance into the handler.\nMy aim for this article is to dissect dependency injection into smaller chunks to understand how it works.\nThe initial code for the project is given below. (main.go)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;os\u0026#34; ) func main() { logger := log.New(os.Stdout, \u0026#34;log \u0026#34;, log.LstdFlags|log.Ltime|log.Lshortfile) mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, func(rw http.ResponseWriter, r *http.Request) { logger.Printf(\u0026#34;Inside handler\u0026#34;) rw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain; charset=utf-8\u0026#34;) rw.WriteHeader(http.StatusOK) rw.Write([]byte(\u0026#34;Hello world\u0026#34;)) }) http.ListenAndServe(\u0026#34;:8080\u0026#34;, mux) }   Note that new instance of logger has been initialised in line 10.\nThe flags log.LstdFlags define which text to prefix to each log entry generated by the Logger.\nlog.Ltime represents the time at which the log was generated and the log.Lshortfile represents the name of the file from which the log was printed.\nOn executing the file we get the following output.\nlog 2021/02/01 16:44:03 main.go:15: Inside root\nlog 2021/02/01 16:44:03 main.go:15: Inside root\nThe logger instance was generated in main.go file. Suppose we want to create a new router called home. Instead of creating a new instance of logger we can simply inject it into the router. This is where the dependency injection comes into the picture.\nWe create a new package that handles the logic of /home route. The new package is home package. In the home.go file, we add the following code.\nDependency Injection Step 1 : Create a Handler of type struct and initialise a logger variable of the type log.Logger 1 2 3  type Handlers struct { logger *log.Logger }   Step 2 : Create a function constructor to initialise the logger variable. It returns an address of the initialised Handler. 1 2 3 4 5  func NewHandlers(logger *log.Logger) *Handlers { return \u0026amp;Handlers{ logger: logger, } }   Step 3: Handle method takes implementation of http.Handler interface as the second argument, hence serveHttp method has been intialised with the code logic (logger is accesses inside the function). 1 2 3 4 5 6  func (h *Handlers) ServeHTTP(rw http.ResponseWriter, r *http.Request) { h.logger.Printf(\u0026#34;Inside home\u0026#34;) rw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain; charset=utf-8\u0026#34;) rw.WriteHeader(http.StatusOK) rw.Write([]byte(\u0026#34;from home page\u0026#34;)) }   Step 4: Instance of handler is intialised and assigned to a new variable passed to the /home router 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  func main() { logger := log.New(os.Stdout, \u0026#34;log \u0026#34;, log.LstdFlags|log.Ltime|log.Lshortfile) h := homePage.NewHandlers(logger) mux := http.NewServeMux() mux.HandleFunc(\u0026#34;/\u0026#34;, func(rw http.ResponseWriter, r *http.Request) { logger.Printf(\u0026#34;Inside root\u0026#34;) rw.Header().Set(\u0026#34;Content-Type\u0026#34;, \u0026#34;text/plain; charset=utf-8\u0026#34;) rw.WriteHeader(http.StatusOK) rw.Write([]byte(\u0026#34;Hello world\u0026#34;)) }) mux.Handle(\u0026#34;/home\u0026#34;, h) http.ListenAndServe(\u0026#34;:8080\u0026#34;, mux) }   The output is\nlog 2021/02/01 18:48:55 main.go:18: Inside handler\nlog 2021/02/01 18:49:04 home.go:19: Inside home\nWe can clearly see that the logger instance is initialised once and injected into wherever necessary.\nFind the source code here https://github.com/adhithyakrishna/go-dependency-injection ","description":"An article about dependency injection in golang","id":4,"section":"tech","tags":null,"title":"Dependency injection in golang","uri":"https://adhithyakrishna.github.io/tech/golang/dependencyinjection/"},{"content":"  Contains Notes for the book Java concurrency in practice - https://jcip.net/)\nRunning a single program at a time was inefficient use of expensive and scarce computer resources\nProcesses Processes are isolated, independently executing programs to which operating system allocates resources such as memory, file handles and security credentials.\nProcesses communicate with one another through a variety of coarse-grained communication mechanism: sockets, signal handlers, shared memory, semaphores and fils.\nMulti program execution Several motivating factors led to the development of OS that allowed multiple programs to execute simultaneously.\n  Resource Utilization: Programs have to sometimes wait for external operations such as input or output. While waiting for external operations, it is more efficient to use the wait time to let another program run.\n  Fairness: Multiple users and programs may have equal claims on machine\u0026rsquo;s resources. It is preferable to let the users share the resources via finer-grained time slicing rather than keeping them wait until the current program completes exectuion.\n  Convenience: It is easier to write several program that each perform a single task and have them coordinate with each other as necessary than to write a single program that performs all the tasks.\n  The same factors that motivated the development of processes also motivated the development of threads.\nThreads Threads are light weight processes, most operating systems treat threads, not processes as the basic unit of scheduling.\n Allow multiple streams of program control flow to co-exist within a process. They share a process wide resource such as memory and file handles. Each thread has its own program counter, stack and local variables. Multiple threads within the same program can be scheduled simultaneously on multiple CPUs.   Single vs Multithreaded: Java Concurrency in practice   In absence of explicit coordination threads execute simultaneously and asynchronously with respect to one another. Since threads share the memory addresss space of their owning process, all threads within a process have access to same variables and allocate objects from the same heap allowing finer grained data sharing than inter-process mechanisms.\nBut without explicit synchronization to coordinate access to shared data, a thread may modify variables that another thread is in the middle of using, with unpredicatable results.\n","description":"Contains Notes for the book Java concurrency in practice - https://jcip.net/)","id":5,"section":"tech","tags":null,"title":"Ch01 - Introduction","uri":"https://adhithyakrishna.github.io/tech/java_concurrency_in_practice/introduction/introduction/"},{"content":"  Concurrency is more about achieving thread-safety, than it is about creating \u0026amp; managing threads. Those are mechanisms, but at its core, concurrency aims to encapsulate shared mutable state from uncontrolled concurrent access.\nState of an object An object\u0026rsquo;s state encompasses any data that can affect its externally visible behavior. An object\u0026rsquo;s state is its data, stored in state variables such as instance or static fields.\nAn object\u0026rsquo;s state may include fields from other dependant objects. Example a HashMap\u0026rsquo;s state is partially stored in the HashMap object itself, but also in many Map.Entry objects.\nShared: Variable could be accessed by multiple threads.\nMutable: Value could change during its lifetime.\nThread safety Threadsafety is about trying to protect the data from uncontrolled concurrent access. Whether an object needs to be thread-safe depends on whether it will be accessed from multiple threads. This is a property of how an object is used in a program and not what it does.\nMaking an object thread-safe requires using synchronization to coordinate access to its mutable state. Failing to do so could result in data corruption and other undesirable consequences.\nWhen more than one thread accesses a given state variable and one of them might write to it, they all must coordinate their access to it using synchronization.\nThe primary mechanism for synchronization in Java is the synchronized keyword, which provides exclusive locking, but the term \u0026lsquo;synchronization\u0026rsquo; also includes the use of\n1)volatile variables\n2) Explicit locks\n3) Atomic variables\nA program that omits the needed synchronization might appear to work, passing its test and performing well for years, but it is still broken and may fail at any moment. If multiple threads access the same mutable state variable without appropriate synchronization, the program is broken and there are three ways to fix it:\n Dont share the state variables across threads. Make the state variable immutable. Use synchronization whenever accessing the state variable.   If it easier to design a class to be thread-safe than to retrofit it for thread safety later.\nObject oriented techniques can help write well-organized, maintainable classes - such as encapsulation and data hiding - can also help create thread-safe classes.\nJava does not force developers to encapsulate state - A state can be stored in public fields or public static fields or publish a reference to an otherwise internal object, but the better encapsulated the program state is, the easier it is to make the program thread-safe. The less code that has access to a particular variable, the easier it is to ensure that all of it uses proper synchronization.\nWhen designing thread-safe classes, good object-oriented techniques - encapasulation, immutability and clear specification of invariants are helpful.\nInvariant means something that should stick to its conditions no matter whatever changes or whoever uses/transforms it.\n There might be times when good OO design techniques are at odds with real-world requirements.\n Rules of good design need to be compromised for the sake of performance or for the same of backward compatability with legacy code. Abstraction and Encapsulation are at odds with performance - (although not nearly as often).  It is a good practice to make the code right and then make it fast. Pursue optimization only if needed and those same measurements tell you that your optimizations actually made a difference under realistic conditions.\nA program that consists entirely of thread-safe classes may not be thread-safe. The concept of a thread-safe class makes sense only if the class encapsulates its own state.\nThread safety may be a term that is applied to code, but it is about state, and it can be applied to the entire body of code that encapsulates its state, which may be an object or an entire program. What is Thread Safety? The heart of any reasonable definition of thread safety is its concept of correctness.\n*Correctness means that a class conforms to its specification. A good specification defines invariants constraining an object\u0026rsquo;s state and post - conditions describing the effects of its operations.\nA class is thread-safe if it behaves correctly when accessed from multiple threads, regardless of the scheduling or interleaving of the execution of those threads by the runtime enviornment, and with no additional synchronization or other coordination on the part of the calling code. If an object is correctly implemented, no sequence of operations - calls to public methods and reads or writes of public fields - should be able to violate any of its invariants or post-conditions.\nNo set of operations performed sequentially or concurrently on instances of a thread-safe class can cause an instance to be an invalid state.\nFrameworks like servlet frameworks create threads and call components from those threads, leaving developers with making the components thread-safe.\nStateless servlet 1 2 3 4 5 6 7  public class StatelessFactorizer implements Servlet { public void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); BigInteger[] factors = factor(i); encodeIntoResponse(resp, factors); } }   StatelessFactorizer in the above example has no fields and references no fields from other classes.\nThe *transient state for a particular computation exists solely in local variables that are stored on thread\u0026rsquo;s stack and are accessible only to the executing thread.\nOne thread accessing a StatelessFactorizer cannot influence the result of another thread accessing the same StatelessFactorizer because two threads do not share state. It is as if they were accessing different instances.\nSince the actions of a thread accessing a stateless object cannot affect the correctness of operations in other threads, stateless objects are thread-safe.\nStateless objects are always thread safe. If its only when servlet wants to remember things from one request to another that the thread safety requirement becomes and issue.\nAtomicity Adding one element of state to a stateless object would make it not thread-safe, even though it worked just fine in a single-threaded environment.\nIn this example, a variable count is introduced to keep track of the number of request processed. Though this may work just fine in a single threaded environment, it is susceptible to lost updates.\ncount variable as noted previously, despite its shorthand syntax has 3 discrete operations (read-modify-write operation).\n Fetch the current value. Add one to it. Write the new value back.  1 2 3 4 5 6 7 8 9 10  public class UnsafeCountingFactorizer implements Servlet { private long count = 0; public long getCount() { return count; } public void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); BigInteger[] factors = factor(i); ++count; encodeIntoResponse(resp, factors); } }   If two threads increment the counter simultaneously, without synchronization, the counter would not give an accurate result. The posibility of incorrect results in the presence of unlucky timing is called a race condition.\nRace conditions A race condition occurs when the correctness of the computation depends on lucky timing (relative timing or interleaving of multiple threads by runtime).\ncheck-then-act check-then-act is a type of race condition that uses a potentially stale observation to make a decision or perform a computation. The observation could have even become invalid between the time it was observed and the time an action was take on it.\nExample: Lazy intialization\n1 2 3 4 5 6 7 8 9  @NotThreadSafe public class LazyInitRace { private ExpensiveObject instance = null; public ExpensiveObject getInstance() { if (instance == null) instance = new ExpensiveObject(); return instance; } }   The goal of lazy initialization is to defer intializing an object until it is actually needed at the same time making sure that it is initialized only once.\nThe getInstance() method checks whether the expensive object has been initialized, in this case it returns the existing instance, otherwise it creates a new instance and returns it retaining a reference so that it can be used for future invocations (to avoid expensive code paths).\nWhen two threads A and B execute getInstance() at the same time. \u0026lsquo;A\u0026rsquo; sees that instance is null and initiate a new object. \u0026lsquo;B\u0026rsquo; also checks if instance is null. The state of instance depends on\n Timing (which is unpredictable) Vagaries of scheduling How long A takes to initiate the ExpensiveOject and set the instance field.  \u0026lsquo;B\u0026rsquo; may again initialize a new instance even though getInstance() was supposed to return the same instance.\nRace conditions does not always result in failure but can cause serious problems. As an example, different instances from multiple invocatiosn could cause registrations to be lost or multiple activities to have inconsistent views of the set of registered objects.\nread-modify-write As we saw previously ++count is not an atomic operation. To properly increment the counter, the current thread must know its previous value and make sure no other thread is changing or using the value in the middle of the update.\nCompounded Actions Both read-modify-write and check-then-act (collectively refered to as compound actions) contains a sequence of operations that need to be atomic or indivisible, relative to other operations on the same state (i.e) sequences of operations that must be executed atomically inorder to remain thread safe.\nTo avoid race conditions, there must be a way to prevent other threads from using a variable while we are in the middle of modifying it, so we can ensure that other threads can observer or modify the state only before we start or after we finish but not in the middle.\nAn atomic operation is one that is atomic with respect to all operations, including itself, that operate on the same state.\nOperations A and B are atomic with respect to each other if, from the perspective of a thread t1 executing operation A, when another thread t2 executes B, either all of B has executed or none of it has.\n The CountingFactorizer can be made atomic by using java.util.concurrent.atomic package that contains atomic variable classes for effecting atomic state transition on numbers and object references.\nBy replacing the long counter with an AtomicLong, all actions that access the counter state are atomic. Because the state of the servlet is the state of the counter and the counter is thread-safe the servlet is once again thread-safe.\nWhere practical, use existing thread-safe objects, like AtomicLong, to manage class\u0026rsquo;s state. It is simpler to reason about the states and state transition for existing thread-safe objects than it is for arbitary state variables, and makes it easy to maintain and verify the thread safety. Locking Adding one more thread-safe state variable to the class will not make it thread-safe\nThe definition of thread safety requires that invariants be preserved regardless of timing or interleaving of operations in multiple threads.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class UnsafeCachingFactorizer implements Servlet { private final AtomicReference\u0026lt;BigInteger\u0026gt; lastNumber = new AtomicReference\u0026lt;BigInteger\u0026gt;(); private final AtomicReference\u0026lt;BigInteger[]\u0026gt; lastFactors = new AtomicReference\u0026lt;BigInteger[]\u0026gt;(); public void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); if (i.equals(lastNumber.get())) encodeIntoResponse(resp, lastFactors.get() ); else { BigInteger[] factors = factor(i); lastNumber.set(i); lastFactors.set(factors); encodeIntoResponse(resp, factors); } } }   The above example is responsible for improving the performance of the servlet by caching the most recently computed result, just in case two consecutive clients request factorization of the same number. To implement this, the last number factored and its factors needs to be remembered.\nUsing atomic references, both lastNumber and lastFactor cannot be updated simultaneously. Even though each call to set is atomic, there is still a window of vulnerability when one has been modified and the other has not, and during that time, other threads could see that the invariant does not hold. Similarly, two values cannot be fetched simultaneously, between the time when thread A fetches the two values, thread B could have changed them and again A may observe that the invariant does not hold.\nTo preserve state consistency, update related state variables in a single atomic operation. Reentrancy Reentrancy means that locks are acquired on a per-thread rather than per invocation basis.\nWhen a thread requests a lock that is already held by another thread, the requesting thread blocks. But since intrinsic locks are reentrant, if a thread tries to acquire a lock that it already holds, the request succeeds.\nReentrancy is implemented by associated each lock with an acquisition count and an owning thread.\nWhen a thread acquires the lock (previously unheld lock) the JVM records the owner and sets the acqusition count to 1. If the same thread acquires the lock again, the count is incremented and when the owning thread exists the synchonrized block the count is decremented. When the counter becomes zero, the lock is released.\nReentrancy facilitates encapsulation of locking behavior and thus simplifies the development of object-oriented concurrent code.\n1 2 3 4 5 6 7 8 9 10 11  public class Widget { public synchronized void doSomething() { ... } } public class LoggingWidget extends Widget { public synchronized void doSomething() { System.out.println(toString() + \u0026#34;: calling doSomething\u0026#34;); super.doSomething(); } }   In the above example calls to the super class method would deadlock without re-entrant locks. Re-entrancy saves us from this deadlock situation.\nGuarding state with locks Because locks enable serialized access (Serializing access means threads take turns accessing the object exclusively, rather than doing concurrently) to the code paths they guard, we can use them to construct protocols for guaranteeing exclusive access to the shared state.\nCompound actions on shared state such as incrementing hit counter (read-modify-write) or lazy initialization (check-then-act) must be atomic to avoid race conditions.\nJust wrapping the compound action with a synchronized block is not sufficient.\n If synchronization is used to coordinate access to a variable, it is needed everywhere that variable is accessed. When using locks to coordinate access to a variable, the same lock must be used wherever that variable is accessed.  For each mutable state variable that may be accessed by more than one thread, all access to that variable must be performed with the same lock held. In this case, we say that the variable is guarded by that lock. Every shared, mutable variable should be guarded by exactly one lock and should be made clear to maintainers which lock it is. A common locking convention is to encapsulate all mutable state within an object to protect it from concurrent access by synchronizing any code path that access mutable state using the object\u0026rsquo;s intrinsic lock. It is easy to subvert this locking protocol accidentally by adding a new method or code path and forgetting to use synchronization.\nAdding synchronization to every method is not enough. For example, put-if-absent operation has a race condition, even though both contains and add are atomic (When multiple operations are combined into a compound action).\n1 2  if (!vector.contains(element)) vector.add(element);   At the same time, synchronizing every method can lead to liveness or performance problems.\nLiveness and Performance It is easy to improve the concurrency of a component while maintaining thread safety by narrowing the scope of synchronized block. However, the scope of the synchronized block should not be too small - an atomic operation should not be divided into to more than one synchronized block.\nIt is reasonable to exclude long-running operations that do not affect shared state so that other threads are not prevented from accessing the shared state while the long-running operation is in progress.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  @NotThreadSafe public class UnsafeCachingFactorizer implements Servlet { private final AtomicReference\u0026lt;BigInteger\u0026gt; lastNumber = new AtomicReference\u0026lt;BigInteger\u0026gt;(); private final AtomicReference\u0026lt;BigInteger[]\u0026gt; lastFactors = new AtomicReference\u0026lt;BigInteger[]\u0026gt;(); public void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); if (i.equals(lastNumber.get())) encodeIntoResponse(resp, lastFactors.get() ); else { BigInteger[] factors = factor(i); lastNumber.set(i); lastFactors.set(factors); encodeIntoResponse(resp, factors); } } }   The above example has race conditions.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  @ThreadSafe public class SynchronizedFactorizer implements Servlet { @GuardedBy(\u0026#34;this\u0026#34;) private BigInteger lastNumber; @GuardedBy(\u0026#34;this\u0026#34;) private BigInteger[] lastFactors; public synchronized void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); if (i.equals(lastNumber)) encodeIntoResponse(resp, lastFactors); else { BigInteger[] factors = factor(i); lastNumber = i; lastFactors = factors; encodeIntoResponse(resp, factors); } } }   In the above example, the servlet caches the last result but has unacceptable concurrency. Only one thread can use the servlet at a time, defeating the purpose of using servlets.\n Serialized access: https://jcip.net/   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  @ThreadSafe public class CachedFactorizer implements Servlet { @GuardedBy(\u0026#34;this\u0026#34;) private BigInteger lastNumber; @GuardedBy(\u0026#34;this\u0026#34;) private BigInteger[] lastFactors; @GuardedBy(\u0026#34;this\u0026#34;) private long hits; @GuardedBy(\u0026#34;this\u0026#34;) private long cacheHits; public synchronized long getHits() { return hits; } public synchronized double getCacheHitRatio() { return (double) cacheHits / (double) hits; } public void service(ServletRequest req, ServletResponse resp) { BigInteger i = extractFromRequest(req); BigInteger[] factors = null; synchronized (this) { ++hits; if (i.equals(lastNumber)) { ++cacheHits; factors = lastFactors.clone(); } } if (factors == null) { factors = factor(i); synchronized (this) { lastNumber = i; lastFactors = factors.clone(); } } encodeIntoResponse(resp, factors); } }   By narrowing the scope of the synchronized block, concurrency of the servlet can be improved while maintaining thread safety.\nThe above example uses two synchronized block, each limited to a short section of code.\n One guards the check-then-act that tests whether we can just return the cached result. The other guards the update of cached number and the cached factors.  The portions of code that are outside the synchronized blocks operate exclusively on local variables, which are not shared across threads and therefore do not require synchronization.\nAcquiring and releasing a lock has some overhead, so it is undesirable to break down synchronized blocks too far (even though it would not compromize atomicity).\nCachedFactorizer holds the lock when accessing state variables and for the duration of compound actions but releases it before executing the potentially long-running factorization operation. This preserves thread safety without affecting concurrency.\nwhen implementing a synchronization policy, resist the temptation to prematurely sacrifice simplicity (potentially compromising safety) for the sake of performance. Holding a lock for a long time, either due to compute-intensive tasks or due to a blocking operation, introduces the risk of liveness or performance problems.\nAvoid holding locks during lengthy computations or operations at risk of not completing quickly such as netowrk or console I/O.\n ","description":"Contains Notes for the book Java concurrency in practice - https://jcip.net/)","id":6,"section":"tech","tags":null,"title":"Ch01 - Thread Safety","uri":"https://adhithyakrishna.github.io/tech/java_concurrency_in_practice/fundamentals/thread_safety/"},{"content":"  Contains Notes for the book Java concurrency in practice - https://jcip.net/)\nBenefits of threads Proper utilization of thread can\n Reduce development and maintenance cost. Improve the performance of complex applications.  Threads are useful in GUI applications for improving the responsiveness of the user interface. In server applications, threads help in improving the resource utilzation and throughput.\nSince the basic unit of scheduling is the thread. A single threaded program can run on at most one processor at a time. When a single threaded program is run on a 100 processor system, it is giving up access to 99%.\nWhen designed properly, a multithreaded program can improve throughput by utilizing available processor resources more effectively.\nUsing multiple threads can help achieve a better throughput on a single processor system as well. When a thread is waiting for the I/O to complete, another thread can still run allowing the application to make progress during the blocking I/O.\nAssigning a thread to each type of task will make it look like its sequential and insulates domain logic from the details of\n Scheduling Interleaved operations Asynchronous I/O Resource waits  A complicated async workflow can be decomposed into a number of simpler synchronous workflows, each running in a seperate thread, interacting with each other at a specific synchronization points.\nExample: RMI (Remote Method Invocation):\nThe framework handles the details of\n Request management Thread creation Load balancing Dispatching portions of the request handling to appropriate app component at the appropriate point in the work-flow.  Servlet writers need not worry about how many requests are being processed at the same time or whether the socket input and output streams block. When a servlet\u0026rsquo;s service method is called in response to a web client, it can process the request synchronously as if it were a single threaded program, greatly simplifying the component development and reduce the learning curve of such frameworks.\nA server appliation that is single threaded would require non-blocking I/O which is more complicated and error-prone than synchronous I/O.\n","description":"Contains Notes for the book Java concurrency in practice - https://jcip.net/)","id":7,"section":"tech","tags":null,"title":"Ch02 - Benefits of Threads","uri":"https://adhithyakrishna.github.io/tech/java_concurrency_in_practice/introduction/benefits_of_threads/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nContainer orchestration Kubernetes is a Container Orchestration technology. Docker has its own container orchestraction - docker swarm. There is also MESOS from Apache.\nThe process of automatically deploying and managing containers (scaling up when load increases and scaling down when load decreases) is known as Container Orchestration.\nAdvantages of container orchestration\n Application is highly available, since there are multiple instances of the application running on different nodes. User traffic is load balanced across various containers. When demand increases, deploy more instances of the application seamlessly this can be done at the service level. When we run out of hardware, we can scale the number of nodes up/down without having to take down the application. All of the above can be done with a set of declarative object configuration files.  Kubernetes components Nodes Node is a machine (physical or virtual) on which k8s is installed. A node is worker machine and this is going to hold the containers launched by kubernetes.\n K8s Nodes: https://www.udemy.com/course/learn-kubernetes/   Cluster Cluster is a set of nodes grouped together. This way, even if one node fails, the application is still accessible from other nodes.\nMultiple nodes would help with sharing load as well.\nMaster Master is another node with kubernetes installed in it and is configured as a master. The master watches over the nodes in the cluster and is responsible for the actual orchestraction of containers on the worker nodes.\nFew responsibilites of master node\n Responsible for managing the cluster. Stores the information about the members of the cluster. Monitor nodes. Moving the workload of the failed nodes to another worker nodes.  Components of Kubernetes (Control plane) When a k8s is installed on a system, the following componenets are also installed\n K8s Components: https://www.udemy.com/course/learn-kubernetes/   1) An API server - An API server acts as a front-end for kubernetes. The users, management devices, CLI all talk to the API server to interact with kubernetes.\n2) An ETCD service - It is a reliable key-value store to store all the data used to manage the cluster. ETCD stores the information of multiple nodes and multiple masters in the k8s cluster in a distributed manner. ETCD is also responsible for implementing locks within the cluster to ensure there are no conflicts between the masters.\n3) A Kubelet service - It is an agent that runs on each node in the cluster. It is responsible for making sure that containers are running on the nodes as expected.\n4) A Container runtime - An underlying software that is used to run the containers. (Docker)\n5) Controllers - They are the brain behind the orchestration. They notice and respond when the nodes, containers or endpoints go down. The controllers would make decisions to bring up new containers in such case.\n6) Schedulers - Reponsible for distributing work or containers across multiple nodes. It looks for newly created containers and assigns them to Nodes.\nThe following factors are taken into account for scheduling decisions\n Induvidual and collective resource requirements Hardware/software/policy constraints Affinity and anti-affinity specifications Data locality Inter-workload interference deadlines  Master vs Nodes  Master vs worker nodes: https://www.udemy.com/course/learn-kubernetes/   The master node has\n Kube-apiserver installed ETCD Control manager Scheduler and more.  Worker node has\n Container run time installed. Kubelet agent - provides health information of the worker node to the master and carry out the actions requested by the master on the worker nodes.  Kubectl (kube control) Tool used to deploy and manage applications on a Kubernetes cluster\n Provide cluster information Get status of nodes in the cluster  Pod Kubernetes does not deploy containers directly on the worker nodes. The containers are encapsulated into a kubernetes objects known as pods. A Pod is a single instance of an application and is the smallest object that can be created in kubernetes.\nTo scale up an application, we create a new pod instead of creating additional container inside of an existing pod. A pod can hold additional containers as well (usually not of the same kind). The additional container can be a helper container that supports the main application. The two containers can communicate with each other directly by referring to each other as localhost since they share the same network namespace. They share the same storage space as well.\n","description":"Kubernetes architecture","id":8,"section":"tech","tags":null,"title":"Kubernetes architecture","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/k8s_architecture/"},{"content":"This article explains embedding interfaces concept in golang. We first begin by writing the main crux of the code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  type Animal struct { Dog } type Dog struct { } func (d Dog) speak() { fmt.Println(\u0026#34;woof\u0026#34;) } func main() { d := Animal{Dog{}} d.speak(); v := Animal{} v.speak(); }   In the above code we declare a type of struct named Dog. There is a method embedded to the Dog struct called speak.\nWe declare a new struct Animal, which has Dog as one of if its fields. Now, All the methods embedded on the struct Dog can be accessed by creating a variable for the struct type Animal (Line 14).\nThough this works fine, the problem here is, the struct Animal has a field Dog hardcoded to it. Suppose we have to include a cat, we have to then alter the struct Animal to include cat. It doesnt end there, we\u0026rsquo;ll also have to modify the variable initialisation to include Cat. Now, since both dog and cat has the function speak we will have to explicitly specify which function are we intending to call. Code including cat is given below.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  type Animal struct { Dog Cat } type Dog struct { } func (d Dog) speak() { fmt.Println(\u0026#34;woof\u0026#34;) } type Cat struct { } func (c Cat) speak() { fmt.Println(\u0026#34;meow\u0026#34;) } func main() { d := Animal{ Dog{}, Cat{}, } d.Cat.speak(); }   To make it easy for us to swap between different animals, or include multiple animals, we can make use of Interfaces.\nInterfaces Step 1: Create a type of interface that encompasses the common functionalites. 1 2 3  type Language interface { speak() }   Now, any type that implements speak function is an implementation of the Language interface.\nStep 2: Create a type of struct Dog, and implement the functions of the interface. 1 2 3 4 5  type Dog struct {} func (d Dog) speak() { fmt.Println(\u0026#34;Woof\u0026#34;) }   Step 3: Include the interface as a field to the Animal struct 1 2 3  type Animal struct { Language }   Now, any struct that implements the speak function can be initialised to the Language field during declaration. We need not disturb the Animal struct again.\nInvoking the speak function for Dog is just a matter of initialising the variable with the struct Animal with any one of the implementations of the Language interface as below.\n1 2  d := Animal{Dog{}} d.speak();   Including a new animal is easy. All we have to do is, create a new struct (Ex. Cat), embed a function speak() to the struct.\n1 2 3 4 5  type Cat struct {} func (d Cat) speak() { fmt.Println(\u0026#34;Woof\u0026#34;) }   The realworld advantage to doing this is that, now any time we decide to replace a funcionality, say, we have included some customer specific logic, it is as easy as swapping it with the new struct that implements the interface.\nFull code can be found below\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import \u0026#34;fmt\u0026#34; type Animal struct { Language } type Dog struct {} func (d Dog) speak() { fmt.Println(\u0026#34;Woof\u0026#34;) } type Cat struct {} func (d Cat) speak() { fmt.Println(\u0026#34;Meow\u0026#34;) } type Language interface { speak() } func main() { d := Animal{Dog{}} d.speak(); c := Animal{Cat{}} c.speak(); }   In line 23, Dog can be replaced by Cat and just by swapping, we can include functionality of cat instead of dog.\nThe output is\nWoof\nMeow\nFind the source code here https://gist.github.com/adhithyakrishna/ac72d0d4af806b764d66fda8efec8728 ","description":"An article about embedding in golang","id":9,"section":"tech","tags":null,"title":"Embedding Interfaces","uri":"https://adhithyakrishna.github.io/tech/golang/embeddinginterfaces/"},{"content":"  Contains Notes for the book Java concurrency in practice - https://jcip.net/)\nIn the absence of synchronization, the ordering of operations in multiple threads is unpredictable.\nSafety Hazards 1 2 3 4 5 6 7  public class UnsafeSequence { private int value; /** Returns a unique value. */ public int getNext() { return value++; } }   In the above example,value++ is three seperate operations.\n Read the value Add one to it Wrie the new value.  Two threads can call getNext and receive the same value since operations in multiple threads may be arbitarily interleaved by the runtime. The result is that same sequence number is returned from mutliple calls in different threads.\nThe above unsafe sequence example illustrate the common concurrency hazard called race condition.\nSince threads share the same memory address space and run concurrently, they can access or modify variables that other threads might be using. Convenience here is, it makes data sharing much easier compared to other inter-thread communication mechanisms. The risk here is, threads can be confused by having data change unexpectedly.\nAllowing multiple threads to access and modify the same variables will introduce the element of non sequentiality into an otherwise sequential programming model.\nFor a multithreaded program to be predictable, access to shared variables must be properly co-ordinated so that the threads do not interfere with one another.\n1 2 3 4 5 6  public class Sequence { private int nextValue; public synchronized int getNext() { return nextValue++; } }   Unsafesequence can be fixed by making getNext() a synchronized method.\nIn absence of synchronization, the compiler, hardware and runtime are allowed to take substantial liberties with the timing and ordering of actions such as caching variables in registers or processor-local caches. These tricks are in aid of better performance and are generally desirable but developer has to clearly identify where the data is being shared across threads so these optimizations dont undermine safety.\nLiveness Hazards Use of threads introduces additional form of liveliness failure.\nSafety -\u0026gt; nothing bad ever happens\nliveliness -\u0026gt; something good eventually happens.\nA liveliness failure occurs when an activity gets into a state such that it is permanently unable to make forward progress. Example deadlock, starvation and livelock.\nPerformance Hazards Mutlithreaded programs are subject to all performance hazards of single threaded programs and to others as well that are introduced by the use of threads.\nContext-switches when the scheduler suspends the active thread temporarity so another thread can run - have significant costs. Such as\n Saving and restoring execution context Loss of locality CPU time spent scheduling threads instead of running them.  When threads share data, they must use synchronization mechanisms that can inhibit\n Compiler optimizations Flush Invalidate memory caches Create synchronization traffic on memory bus.  All of the above factors introduce additional performance costs.\nThreads are Everywhere Every java app uses threads. When JVM starts, it creates threads for JVM house keeping tasks and main thread for running main method.\nWhen concurrency is introduced into an application by a framework, it is usually impossible to restrict the concurrency awareness to the framework code. Framework by nature make callbacks to the application components that in turn access the application state.\nSimilary the need for thread safety does not end with the components called by the framework - it extends to all code paths that access the program state accessed by the components. Thus the need for thread safety is contagious.\nObjects accessed by the tasks themselves should be made thread-safe, encapsulating the thread safety within the shared objects.\n","description":"Contains Notes for the book Java concurrency in practice - https://jcip.net/)","id":10,"section":"tech","tags":null,"title":"Ch03 - Risks of threads","uri":"https://adhithyakrishna.github.io/tech/java_concurrency_in_practice/introduction/risks_of_threads/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nYaml introduction According to yaml.org, \u0026ldquo;YAML is a human-friendly, data serialization standard for all programming languages.\u0026quot;\nYaml is used to create kubernetes configurations\nStructure of YAML file Key Value Pair The basic type of entry in a YAML file is of a key value pair. After the Key and colon there is a space and then the value.\nFruit: Apple Vegetable: Radish Liquid: Water Array/List Lists would have a name and a number of items listed under it. The elements of the list would start with a -. There can be a n of lists, however the indentation of various elements of the array matters a lot.\nFruits: - Orange - Banana - Mango Vegetables: - Potato - Tomato - Carrot Dictionary/Map A more complex type of YAML file would be a Dictionary/Map.\nBanana: Calories: 200 Fat: 0.5g Carbs: 30g Grapes: Calories: 100 Fat: 0.4g Carbs: 20g It is important to indent Yaml properly. Improper indentation would break a sibling / parent relationship between the properties. Advanced YAML structures List containing a list of dictionaries. - Fruits: - Banana: Calories: 105 Fat: 0.4g Carbs: 27g - Grape: Calories: 62 Fat: 0.3g Carbs: 16g - Vegetables: - Potato: Calories: 105 Fat: 0.4g Carbs: 27g Dictionary in Dictionary Banana: type: name: musa Calories: 200 Fat: 0.5g Carbs: 30g A list is ordered\nA dictionary is unordered ","description":"Yaml Introduction","id":11,"section":"tech","tags":null,"title":"Yaml Introduction","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/yaml_introduction/"},{"content":"This article is a continuation to the previous article about Embedding interfaces found here\nWe start from the crux of the previous code.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import \u0026#34;fmt\u0026#34; type Animal struct { Language } type Dog struct {} func (d Dog) speak() { fmt.Println(\u0026#34;Woof\u0026#34;) } type Cat struct {} func (d Cat) speak() { fmt.Println(\u0026#34;Meow\u0026#34;) } type Language interface { speak() } func main() { d := Animal{Dog{}} d.speak(); c := Animal{Cat{}} c.speak(); }   Now, Let us say, we work for a client who wants add a functionality. It may be something like, adding a prefix to the language spoken by the animal.\nTo do that, we can make use of the concept called interface chaining.\nDeclare a type struct that includes the interface as one of its field. It should also include implementations of the speak function. 1 2 3 4 5 6 7 8  type Initiator struct { Language } func (i Initiator) speak() { fmt.Print(\u0026#34;The animal says : \u0026#34;, i) i.Language.speak() }   Now Inititator struct implements the language interface. Since it includes, Language interface as one of its fields, chaining is very easy to do.\n1 2  c := Animal{Initiator{Cat{}}} c.speak()   The Initiator functionality has been chained into the variable declaration. Now everytime a speak function is called on the intialised variable, first, the speak function in the initiator struct would be called and then, the speak function in the Cat struct would take place.\nFull code is given below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  package main import \u0026#34;fmt\u0026#34; type Animal struct { Language } type Dog struct{} func (d Dog) speak() { fmt.Println(\u0026#34;Woof\u0026#34;) } type Cat struct{} func (d Cat) speak() { fmt.Println(\u0026#34;Meow\u0026#34;) } type Language interface { speak() } type Initiator struct { Language } func (i Initiator) speak() { fmt.Print(\u0026#34;The animal says : \u0026#34;) i.Language.speak() } func main() { d := Animal{Dog{}} d.speak() c := Animal{Initiator{Cat{}}} c.speak() }   The output is\nWoof\nThe animal says : Meow\nFind the source code here https://gist.github.com/adhithyakrishna/ad5cb9b6f4ce1d5bb98407f9502e51ee ","description":"An article about Chaining interfaces in golang","id":12,"section":"tech","tags":null,"title":"Chaining Interfaces","uri":"https://adhithyakrishna.github.io/tech/golang/chaininginterfaces/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nKubernetes definition file A Kubernetes definition file always contains 4 top level fields. These are required fields\napiVersion: kind: metadata: . . . spec:  apiVersion - Version of k8s API kind - type of object (pod, replicaset, service, deployment) metadata - data about the object (name and label), it is in the form of a dictionary. Here name is a string value and labels is a dictionary. Labels are useful to identify objects at a later point in time.  metadata: name: myapp-pod labels: app: myapp spec - (specification) where we provide additional information to k8s pertaining to that object. Spec is a dictionary, we can add properties to it, containers in this example, which is a list. The reason this property is a list is because the PODs can have multiple containers within them.  spec: containers: - name: nginx-container image: nginx Few of the kubectl commands kubectl create -f pod-definition.yml kubectl get pods kubectl describe pods ","description":"Yaml for Kubernetes","id":13,"section":"tech","tags":null,"title":"Yaml for Kubernetes","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/yaml_for_k8s/"},{"content":"Golang lets us declare a variable of type functions. In Golang functions are first class citizens. In this article we are going to see how the functions can be used a type in golang.\nDeclaration of the variable 1  type validator func(*User) error   validator is the name of the variable that has a type function which takes the struct User as its argument and returns an error.\nDeclaration of struct and functions on the struct 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  type userValidator struct {} func (uv *userValidator)validateEmail(u *User) error { matched, _ := regexp.MatchString(`^[a-z0-9._%+\\-]+@[a-z0-9.\\-]+\\.[a-z]{2,16}$`, u.email) if !matched { return ErrEmailInvalid } return nil } func (uv *userValidator) isEmpty(u *User) error { if u.email == \u0026#34;\u0026#34; { return ErrEmailEmpty } return nil }   If we observe, we can note that the function argument as well the return type matches the variable we declared above. Now we can pass validator as an argument to different functions and execute them. Below is an example.\n1 2 3 4 5 6 7 8  func runUserValidations(user *User, fns ...validator) error { for _, fns := range fns { if err:=fns(user); err != nil { return err } } return nil }   You can see that, validator is passed as an argument to the runUserValidations functions. The function can be executed by passing an instance of user struct as an argument.\nI have included an example below of how using function types will come in handy while doing multiple functions that validates if an email is valid.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  package main import ( \u0026#34;errors\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;regexp\u0026#34; ) var ( ErrEmailInvalid = errors.New(\u0026#34;email address is not valid\u0026#34;) ErrEmailEmpty = errors.New(\u0026#34;email address is empty\u0026#34;) ) type User struct { email string } type userValidator struct {} type validator func(*User) error func (uv *userValidator)validateEmail(u *User) error { matched, _ := regexp.MatchString(`^[a-z0-9._%+\\-]+@[a-z0-9.\\-]+\\.[a-z]{2,16}$`, u.email) if !matched { return ErrEmailInvalid } return nil } func (uv *userValidator) isEmpty(u *User) error { if u.email == \u0026#34;\u0026#34; { return ErrEmailEmpty } return nil } func runUserValidations(user *User, fns ...validator) error { for _, fns := range fns { if err:=fns(user); err != nil { return err } } return nil } func main() { u := User{ email: \u0026#34;adhithya.awesome@gmail.com\u0026#34;, } uv := userValidator{} err:= runUserValidations(\u0026amp;u, uv.isEmpty, uv.validateEmail) if err != nil { fmt.Println(err) return } fmt.Println(\u0026#34;valid email\u0026#34;) }   If you note line number 52 in the above code you can see how an instance of user struct, initialised with an email is passed to different functions, validated and if there is an error in the validation it prints the error or it prints the email is valid.\nWe can included multiple such functions and calling them is a matter of including them to the runUserValidations functions.\n","description":"An article about function types in golang","id":14,"section":"tech","tags":null,"title":"Function types","uri":"https://adhithyakrishna.github.io/tech/golang/functiontypes/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nReplication controller  Replication controller helps us run multiple instance of a pod in kubernetes cluster, thus providing high availability. Replication controller is capable of ensuring that the specified number of pods are running at all times. It is also capable of load balancing betweening multiple pods to share the loads. It can load balance pods and can do it when pods are in different nodes as well. It allows us to scale the application when demand increases.  apiVersion: v1 kind: ReplicationController metadata: name: myapp-rc labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: frontend spec: containers: - name: nginx-container image: nginx replicas: 3 \u0026gt; kubectl get replicationcontroller Replica Set Replication controller that we saw previously is being replaced by replica set. Replica Set is the recommended way to setup replication.\nOne difference between Replication Controller and Replica Set is, Replica Set requires a selector definition to identify what pods fall under it. Replica Set will take those pods that are already deployed that match the selector definition when creating the replicas.\nReplica Set can also be used to monitor the existing pods and redploy if one of them fails.\nLabeling our pods is essential because there may be hundreds of pods running in our cluster and we can use labels and selectors to identify the pods.\nIf one of the pods fails, Replica Set will use the configuration under the spec property to re-deploy the pod.\napiVersion: apps/v1 kind: ReplicaSet metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 selector: matchLabels: type: front-end kubectl create -f replicaset-definition.yml kubectl get replicaset kubectl delete replicaset myapp-replicaset Scaling the replicaset One of the following commands can be used to scale up the replicaset\nkubectl replace -f replicaset-definition.yml kubectl scale --replicas=6 -f replicaset-definition.yml kubectl scale --replicas=6 replicaset myapp-replicaset Deployments  Deployment provides declarative updates for Pods and RelicaSets When you describe a desired state in a deployment, the deployment controller is capable of changing the actual state to the desired state at a controlled rate. You can define Deployments to create a new ReplicaSets or to remove existing Deployments and adopt all their resources with new Deployments.  Deployments have several interesting use cases which are listed in this page. https://kubernetes.io/docs/concepts/workloads/controllers/deployment/\nDeployment lifecycle First the deployment is created.\nDeployment in turn creates the replicaset.\nReplica Set has in turn creates pods.\nKubectl describe deployment command can be used to find more information about the deployment status.\napiVersion: apps/v1 kind: Deployment metadata: name: myapp-replicaset labels: app: myapp type: front-end spec: template: metadata: name: myapp-pod labels: app: myapp type: front-end spec: containers: - name: nginx-container image: nginx replicas: 3 selector: matchLabels: type: front-end kubectl get all Deployment Rollout and Versioning Whenever a new deployment or upgrade an image to the existing deployment, a rollout is triggered. A rollout is the process of gradually deploying or upgrading your application containers.\nWhen a new deployment is created, it triggers a rollout. A new rollout creates a new Deployment revision (Version 1). When the application is upgraded later, a new deployment revision is created (Version 2).\nThis will help us keep track of the changes made to our deployment and enable us to rollback to the previous version of the deployment if necessary.\nkubectl rollout status kubectl rollout history Deployment Strategies The default deployment strategy is Rollout. There is another strategy called Recreate which as the name implies, deletes all the pods and recreates them bringing the entire service down while doing it. Rollout strategy on the other hand, takes down the older version and brings back the newer version one by one. This way, the application never goes down and the upgrade is seamless.\nTo update the image of the running deployment kubectl set image deployment/myapp-deployment nginx-container=nginx:1.12-perl command can be used.\nDeployment Upgrades When a new deployment is created, it creates a ReplicaSet which inturn creates the number of Pods required to meet the number of replicas. When you upgrade your application, the kubernetes deployment creates a NEW replicaset under the hood and starts deploying the containers there. Taking down the pods in old Replica Set also follow the Rolling Update strategy.\nDeployment rollbacks kubectl rollout undo followed by the name of the deployment will allow you to rollback to a previous version. The deployment will destroy the pods in new replicaset and bring back the older ones in the old replicaset.\nkubectl run nginx --image=nginx the kubectl run command actually creates a deployment. A replicaset and pods are automatically created in the backend.\nList of useful commands \u0026gt; kubectl create -f deployment definition.yml \u0026gt; kubectl create -f deployment definition.yml --record \u0026gt; kubectl get deployments \u0026gt; kubectl apply -f deployment definition.yml \u0026gt; kubectl set image deployment/myapp-deployment nginx=nginx:1.9.1 \u0026gt; kubectl rollout status deployment/myapp-deployment \u0026gt; kubectl rollout history deployment/myapp-deployment \u0026gt; kubectl rollout undo deployment/myapp deployment ","description":"Kubernetes controllers","id":15,"section":"tech","tags":null,"title":"Kubernetes controllers","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/k8s_controllers/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nKubernetes service enable communication between various components within or ourside of the application. Kubernetes Services helps us connect applications with other applications or users.\nServices enable connectivity between the group of pods. For example front-end to the users, connection between the frontend and backend processes and backend to to external data source.\nServices enable Loose coupling between microservices in our application.\nNode Port One of the use case of Nodeport is to listen to a port on the Node and forward requests on that port to a port on the pod running the web application.\nThis type of service is know as NodePort service because the service listens to a port on the Node and forwards requests to Pods.\nNodePorts can only be in a valid range which is from 30000 to 32767.\n K8s Services: https://www.udemy.com/course/learn-kubernetes/   Below terms are from the viewpoint of the service. The service is like a virtual server inside of the node. It has its own ip address.\n TargetPort - The port on the Pod where the actual web server is running - (port 80). This is where the service forwards requests to. Port - Port on the service itself. (Simply referred to as the port). NodePort - Port on the node, which can be used to access the web server externally.  apiVersion: v1 kind: Service metadata: name: spring-boot-service namespace: spring-boot spec: selector: app: spring-boot-deployment ports: - port: 8080 targetPort: 8080 nodePort: 30009 type: NodePort Here the only mandatory field is port. The target port would be the same as port if not specified and nodePort value will be between the 30000 and 32767 range (automatically allocated if not specified).\nWe can do multiple port mappings within a single service.\nLabels and selectors are used to map the pods to the service. When a service is created it looks for matching pods with the labels and finds 3 of them. The service then auto selects all 3 pods to forward the external requests coming from the user. No additional configuration is needed to make this happen.\nThis service acts as a built in load balancer to distribute the load across different pods.\n K8s Services: https://www.udemy.com/course/learn-kubernetes/   Kubernetes creates a service that can spans across all the nodes in the cluster and maps the target port to the same nodeport on all the nodes in the cluster, without having to do any additional configurations.\nThis way the application can be accessed using the IP of any node by using the same port number.\nTo summarize – in ANY case whether it be a single pod in a single node, multiple pods on a single node, multiple pods on multiple nodes, the service is created exactly the same without having to do any additional steps during the service creation.\nWhen PODs are removed or added the service is automatically updated making it highly flexible and adaptive. Once created, you won’t typically have to make any additional configuration changes.\nClusterIP ClusterIP provides a single interface to access pods in a group. A service created for backend pods will help group all the backend pods and provide a single interface for the other pods to access this service, allowing to easily and effectively deploy a microservices based application on a Kubernetes cluster. Similarly, creating additional services for database layer allows the backend pods to access the database layer through this sergice.\nEach service gets an IP and name assigned to it inside the cluster and that is the name that should be used by the other pods to acccess the service. This type of service is known as ClusterIP. ClusterIP is the default type in kubernetes configuration. If we did not specify the type, ClusterIP would be assigned by default.\n K8s Services: https://www.udemy.com/course/learn-kubernetes/   apiVersion: v1 kind: Service metadata: name: back-end spec: type: ClusterIP ports: - targetPort: 80 port: 80 selector: app: myapp type: back-end LoadBalancer Exposes the Service externally using a cloud provider\u0026rsquo;s load balancer.\nOn cloud providers which support external load balancers, setting the type field to LoadBalancer provisions a load balancer for your Service.\napiVersion: v1 kind: Service metadata: name: my-service spec: selector: app.kubernetes.io/name: MyApp ports: - protocol: TCP port: 80 targetPort: 9376 clusterIP: 10.0.171.239 type: LoadBalancer status: loadBalancer: ingress: - ip: 192.0.2.127 Differrence between different services https://stackoverflow.com/questions/41509439/whats-the-difference-between-clusterip-nodeport-and-loadbalancer-service-types\nExcerpts from the above stack overflow link\nYou can access a service from your load balancer\u0026rsquo;s IP address, which routes your request to a nodePort, which in turn routes the request to the clusterIP port. You can acess this service as you would a NodePort or a ClusterIP service as well. A ClusterIP Service is part of a NodePort Service. A NodePort Service is Part of a Load Balancer Service.\nkubectl get services displays the loadbalancer as well as cluster-ip\nminikube service redis-service --url displays the node-ports.\n K8s Services: https://www.udemy.com/course/learn-kubernetes/   ClusterIP - Exposes a service which is only accessible from within the cluster.\nNodePort - Exposes a service via a static port on each node’s IP.\nLoadBalancer - Exposes the service via the cloud provider’s load balancer.\nPods within the cluster can talk to each other through clusterIP.\nTo make a pod accessible from outside the cluster, it will create nodePort. Node port will make use of the clusterIP to do this.\nLoad balancer puts a loadbalancer in front so that the inbound traffic is distributed between node ports.\nIf you want to acccess the service from outside a cluster only Nodeport will be accessible and not clusterIP.\nAdditional reference: https://stackoverflow.com/a/72988866\n","description":"Kubernetes services","id":16,"section":"tech","tags":null,"title":"Kubernetes services","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/k8s_services/"},{"content":"  This notes is for the course Kuberenetes for absolute beginners\nApplication flow  K8s Pods demo: https://www.udemy.com/course/learn-kubernetes/   Voting application We create pods and expose the container port. Please note that all the docker images are pre-built and this demo is to understand how different microservices communicate with each other through k8s services.\nCreate a definition for pod voting-app-pod.yml\napiVersion: v1 kind: Pod metadata: name: voting-app-pod labels: name: voting-app-pod app: demo-voting-app spec: containers: - name: voting-app image: dockersamples/examplevotingapp_vote imagePullPolicy: IfNotPresent ports: - containerPort: 80 restartPolicy: Always Create a Loadbalancer service to expose the application to external world voting-app-service.yml\napiVersion: v1 kind: Service metadata: name: voting-service labels: name: voting-service app: demo-voting-app spec: ports: - port: 80 targetPort: 80 selector: name: voting-app-pod app: demo-voting-app type: LoadBalancer Result application Create a definition for a pod result-app-pod.yml\napiVersion: v1 kind: Pod metadata: name: result-app-pod labels: name: result-app-pod app: demo-voting-app spec: containers: - name: result-app image: dockersamples/examplevotingapp_result imagePullPolicy: IfNotPresent ports: - containerPort: 80 restartPolicy: Always Create a Loadbalancer service to expose the application to external world result-app-service.yml\napiVersion: v1 kind: Service metadata: name: result-service labels: name: result-service app: demo-voting-app spec: ports: - port: 80 targetPort: 80 selector: name: result-app-pod app: demo-voting-app type: LoadBalancer Redis application Create a definition for a pod redis-pod.yml\napiVersion: v1 kind: Pod metadata: name: redis-pod labels: name: redis-pod app: demo-voting-app spec: containers: - name: redis image: redis imagePullPolicy: IfNotPresent ports: - containerPort: 6379 restartPolicy: Always Create a NodePort service for postgres redis-service.yml\napiVersion: v1 kind: Service metadata: name: redis labels: name: redis-service app: demo-voting-app spec: ports: - port: 6379 targetPort: 6379 selector: name: redis-pod app: demo-voting-app type: NodePort Services are created so that the pods can communicate to each other.\nServices should be named based on what other applications are looking for. The name here is set to db because the application looks for service named db (you can see that in the code).\n Postgres application Create a definition for a pod postgres-pod.yml\napiVersion: v1 kind: Pod metadata: name: postgres-pod labels: name: postgres-pod app: demo-voting-app spec: containers: - name: postgres image: postgres:9.4 imagePullPolicy: IfNotPresent env: - name: POSTGRES_USER value: \u0026quot;postgres\u0026quot; - name: POSTGRES_PASSWORD value: \u0026quot;postgres\u0026quot; - name: POSTGRES_HOST_AUTH_METHOD value: trust ports: - containerPort: 5432 restartPolicy: Always Create a NodePort service for postgres postgres-service.yml\napiVersion: v1 kind: Service metadata: name: db labels: name: db-service app: demo-voting-app spec: ports: - port: 5432 targetPort: 5432 selector: name: postgres-pod app: demo-voting-app type: NodePort Worker application Note that thess pod is needed just for internal communication.\nCreate a definition for a pod worker-app-pod.yml\napiVersion: v1 kind: Pod metadata: name: worker-app-pod labels: name: worker-app-pod app: demo-voting-app spec: containers: - name: worker-app image: dockersamples/examplevotingapp_worker imagePullPolicy: IfNotPresent restartPolicy: Always Output  K8s Pods demo: https://www.udemy.com/course/learn-kubernetes/   Application communication (in docker) Note that links is deprecated but this gives an idea of how the applications communicate internally.  K8s Pods demo: https://www.udemy.com/course/learn-kubernetes/   ","description":"Kubernetes services","id":17,"section":"tech","tags":null,"title":"Demo - Voting application 1","uri":"https://adhithyakrishna.github.io/tech/k8s_for_absolute_beginners/k8s_pods_demo/"}]